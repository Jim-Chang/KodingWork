{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a771d12-fe23-4932-9067-a64bfee7ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ebde81-22ee-42cc-9140-d6f58281f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_list = [\n",
    "    {\n",
    "        'name': 'Hyun Bin',\n",
    "        'filename': '玄彬.jpeg',\n",
    "        'encode': None,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Son Ye Jin',\n",
    "        'filename': '孫藝珍.jpeg',\n",
    "        'encode': None,        \n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6047c30e-7fa8-449e-a5df-9e89788cb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in known_face_list:\n",
    "    img = cv2.imread(data['filename'])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    data['encode'] = face_recognition.face_encodings(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8d083-6fd7-4515-8f3d-235dc55b9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(known_face_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde068f5-7a0c-43c5-8cf7-3ed79b3935bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodes = [data['encode'] for data in known_face_list]\n",
    "tolerance = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956abbf-23e8-462e-a020-cb1ccd75598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fn_list = ['孫藝珍-t1.jpeg', '孫藝珍-t2.jpeg', '孫藝珍-t3.jpeg', '玄彬+孫藝珍.jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11773359-4a53-4764-b391-9839720ebdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in test_fn_list:\n",
    "    img = cv2.imread(fn)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    cur_face_locs = face_recognition.face_locations(img)\n",
    "    cur_face_encodes = face_recognition.face_encodings(img, cur_face_locs)\n",
    "    \n",
    "    for cur_face_encode in cur_face_encodes:\n",
    "        face_distance_list = face_recognition.face_distance(known_face_encodes, cur_face_encode)\n",
    "        \n",
    "        min_distance_index = np.argmin(face_distance_list)\n",
    "        if face_distance_list[min_distance_index] < tolerance:\n",
    "            result = known_face_list[min_distance_index]['name']\n",
    "        else:\n",
    "            result = 'unknown'\n",
    "            \n",
    "        distance_with_name_list = [(face_data['name'], round(distance, 4)) for face_data, distance in zip(known_face_list, face_distance_list)]\n",
    "        print(f'辨識檔案: {fn}, 辨識結果: {result}, 特徵距離: {distance_with_name_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47f165-fa71-4334-8441-d0d72066ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_COLOR = (200, 58, 76)\n",
    "WHITE_COLOR = (255, 255, 255)\n",
    "\n",
    "def draw_locations(img, match_results):\n",
    "    for match_result in match_results:\n",
    "        y1, x2, y2, x1 = match_result['location']\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), RED_COLOR, 2)\n",
    "        cv2.rectangle(img, (x1, y2 + 35), (x2, y2), RED_COLOR, cv2.FILLED)\n",
    "        cv2.putText(img, match_result['name'], (x1 + 10, y2 + 25), cv2.FONT_HERSHEY_COMPLEX, 0.8, WHITE_COLOR, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cae8af-9f9a-4b38-ab83-385eab14bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "for fn in test_fn_list:\n",
    "    match_results = []\n",
    "    \n",
    "    img = cv2.imread(fn)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    cur_face_locs = face_recognition.face_locations(img)\n",
    "    cur_face_encodes = face_recognition.face_encodings(img, cur_face_locs, model='large')\n",
    "    \n",
    "    for cur_face_encode, cur_face_loc in zip(cur_face_encodes, cur_face_locs):\n",
    "        face_distance_list = face_recognition.face_distance(known_face_encodes, cur_face_encode)\n",
    "        \n",
    "        min_distance_index = np.argmin(face_distance_list)\n",
    "        if face_distance_list[min_distance_index] < tolerance:\n",
    "            name = known_face_list[min_distance_index]['name']\n",
    "        else:\n",
    "            name = 'unknown'\n",
    "            \n",
    "        match_results.append({\n",
    "            'name': name,\n",
    "            'location': cur_face_loc,\n",
    "        })\n",
    "        \n",
    "    draw_locations(img, match_results)\n",
    "    display(Image.fromarray(img))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d90f4-7fa3-44c2-8f61-6bd63db66c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
