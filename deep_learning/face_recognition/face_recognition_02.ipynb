{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f011ea6-f551-4c2a-b946-2c3f7aaaae2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc7be74-8ee9-46c7-a97c-c1fb97050c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "known_face_list = [\n",
    "    {\n",
    "        'name': 'Hyun Bin',\n",
    "        'filename': '玄彬.jpeg',\n",
    "        'encode': None,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Son Ye Jin',\n",
    "        'filename': '孫藝珍.jpeg',\n",
    "        'encode': None,        \n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea942f1-aa29-4781-badc-462c805fd9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load image data\n",
    "for data in known_face_list:\n",
    "    img = cv2.imread(data['filename'])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    data['encode'] = face_recognition.face_encodings(img)[0]\n",
    "    \n",
    "known_face_encodes = [data['encode'] for data in known_face_list]\n",
    "tolerance = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854ac2e-83c2-4df3-9497-003f83cb8c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_fn_list = ['孫藝珍-t1.jpeg', '孫藝珍-t2.jpeg', '孫藝珍-t3.jpeg', '玄彬+孫藝珍.jpeg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e446d6-3622-421d-8d0e-b7ea2399d7b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 如何儲存 Face Encoding 加速載入？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f768c2-5ad3-4bc1-a398-01d96879b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f51ec-1066-4da6-88c4-73828275ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save known_face_list to dat file\n",
    "with open('faces.dat', 'wb') as f:\n",
    "    pickle.dump(known_face_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65baba2a-5314-4619-8664-d2ed35fd4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load known_face_list from dat file\n",
    "with open('faces.dat', 'rb') as f:\n",
    "    known_face_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424fb564-8308-4609-ab64-bd9386c38d09",
   "metadata": {},
   "source": [
    "## 發現有時會誤判人臉？改用 CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a981099-b9e3-4564-b697-2ad6bcfe99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for fn in test_fn_list:\n",
    "    img = cv2.imread(fn)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    _t = time.time()\n",
    "    \n",
    "    face_recognition.face_locations(img) # use HOG model to detect face locations\n",
    "    \n",
    "    _t1 = time.time()\n",
    "    \n",
    "    face_recognition.face_locations(img, model='cnn') # use CNN model to detect face locations\n",
    "    \n",
    "    print(f'HOG: {round(_t1 - _t, 2)} secs, CNN: {round(time.time() - _t1, 2)} secs') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660301c0-b328-4e83-b576-782d082592cf",
   "metadata": {},
   "source": [
    "## 準確度不夠？增加特徵點數量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19fe78-e604-40d0-a48d-10ff036a50a7",
   "metadata": {},
   "source": [
    "### 使用 68 個特徵點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902dce61-29ec-4b32-8e45-266734372dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_list = [\n",
    "    {\n",
    "        'name': 'Lee',\n",
    "        'filename': 'lee.jpg',\n",
    "        'encode': None,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Pan',\n",
    "        'filename': 'pan.jpg',\n",
    "        'encode': None,        \n",
    "    },\n",
    "]\n",
    "\n",
    "test_fn_list = ['lee-t1.jpg', 'lee-t2.jpg', 'pan-t1.jpg', 'pan-t2.jpg']\n",
    "\n",
    "# load image data by large model of face landmarks\n",
    "for data in known_face_list:\n",
    "    img = cv2.imread(data['filename'])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    data['encode'] = face_recognition.face_encodings(img, model='large')[0]  # use large model of face landmarks\n",
    "    \n",
    "known_face_encodes = [data['encode'] for data in known_face_list]\n",
    "    \n",
    "# face recognition\n",
    "for fn in test_fn_list:\n",
    "    img = cv2.imread(fn)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    cur_face_locs = face_recognition.face_locations(img)\n",
    "    cur_face_encodes = face_recognition.face_encodings(img, cur_face_locs, model='large')  # use large model of face landmarks\n",
    "    \n",
    "    for cur_face_encode in cur_face_encodes:\n",
    "        face_distance_list = face_recognition.face_distance(known_face_encodes, cur_face_encode)\n",
    "        \n",
    "        min_distance_index = np.argmin(face_distance_list)\n",
    "        if face_distance_list[min_distance_index] < tolerance:\n",
    "            result = known_face_list[min_distance_index]['name']\n",
    "        else:\n",
    "            result = 'unknown'\n",
    "            \n",
    "        distance_with_name_list = [(face_data['name'], round(distance, 4)) for face_data, distance in zip(known_face_list, face_distance_list)]\n",
    "        print(f'辨識檔案: {fn}, 辨識結果: {result}, 特徵距離: {distance_with_name_list}, 相差: {round(abs(distance_with_name_list[0][1] - distance_with_name_list[1][1]), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a50592-5bfc-4722-a77a-908d804c34e6",
   "metadata": {},
   "source": [
    "### 使用 5 個特徵點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c865d-a0c9-41b9-a007-4d6915589834",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_list = [\n",
    "    {\n",
    "        'name': 'Lee',\n",
    "        'filename': 'lee.jpg',\n",
    "        'encode': None,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Pan',\n",
    "        'filename': 'pan.jpg',\n",
    "        'encode': None,        \n",
    "    },\n",
    "]\n",
    "\n",
    "test_fn_list = ['lee-t1.jpg', 'lee-t2.jpg', 'pan-t1.jpg', 'pan-t2.jpg']\n",
    "\n",
    "# load image data by large model of face landmarks\n",
    "for data in known_face_list:\n",
    "    img = cv2.imread(data['filename'])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    data['encode'] = face_recognition.face_encodings(img, model='small')[0]  # use small model of face landmarks\n",
    "    \n",
    "known_face_encodes = [data['encode'] for data in known_face_list]\n",
    "    \n",
    "# face recognition\n",
    "for fn in test_fn_list:\n",
    "    img = cv2.imread(fn)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    cur_face_locs = face_recognition.face_locations(img)\n",
    "    cur_face_encodes = face_recognition.face_encodings(img, cur_face_locs, model='small')  # use small model of face landmarks\n",
    "    \n",
    "    for cur_face_encode in cur_face_encodes:\n",
    "        face_distance_list = face_recognition.face_distance(known_face_encodes, cur_face_encode)\n",
    "        \n",
    "        min_distance_index = np.argmin(face_distance_list)\n",
    "        if face_distance_list[min_distance_index] < tolerance:\n",
    "            result = known_face_list[min_distance_index]['name']\n",
    "        else:\n",
    "            result = 'unknown'\n",
    "            \n",
    "        distance_with_name_list = [(face_data['name'], round(distance, 4)) for face_data, distance in zip(known_face_list, face_distance_list)]\n",
    "        print(f'辨識檔案: {fn}, 辨識結果: {result}, 特徵距離: {distance_with_name_list}, 相差: {round(abs(distance_with_name_list[0][1] - distance_with_name_list[1][1]), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7aa18-3ed6-4419-af41-dc3b42c5635f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
